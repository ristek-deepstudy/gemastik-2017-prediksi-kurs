{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI\n"
     ]
    }
   ],
   "source": [
    "print(\"HI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as CV\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier as GB\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "from Database import Database\n",
    "from numpy import array\n",
    "from sklearn.naive_bayes import MultinomialNB as NB\n",
    "import sqlite3\n",
    "import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('berita.db')\n",
    "c = conn.cursor()\n",
    "c.execute(\"SELECT Text,Date,Clock,Sentiment From Berita \")\n",
    "result = c.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = Database()\n",
    "data = {}\n",
    "label = {}\n",
    "for I in result:\n",
    "    session = d.cariSesi(I[1],I[2])[0]\n",
    "    if session not in data:\n",
    "        data[session] = []\n",
    "        label[session] = I[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sorting the chronological order\n",
    "\n",
    "#MeTooLazySoMeBubbleSort\n",
    "\n",
    "chronology = list(data.keys())\n",
    "\n",
    "for I in range(len(data.keys())):\n",
    "    for J in range(I+1,len(data.keys())):\n",
    "        if chronology[I] > chronology[J]:\n",
    "            chronology[I],chronology[J] = chronology[J],chronology[I]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date = [chronology[len(chronology)*I//6-1] for I in range(1,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def balancedTrain(X,y,mode):\n",
    "    '''\n",
    "    mode has two options:\n",
    "    -> 'CV'\n",
    "    then balancedTrain would suit it undersampling method for \n",
    "    cross validation\n",
    "    \n",
    "    -> 'Boosting'\n",
    "    then balancedTrain would suit is sampling method for\n",
    "    boosting    \n",
    "    '''\n",
    "    assert mode == 'CV' or mode == 'Boosting'\n",
    "    balancedX = []\n",
    "    balancedY = []\n",
    "    \n",
    "    index = {}\n",
    "    \n",
    "    assert len(X) == len(y)\n",
    "    \n",
    "    #Mencatat indeks mana yang positif dan mana yang negatif\n",
    "    for I in range(len(X)):\n",
    "        if y[I] not in index:\n",
    "            index[y[I]] = []\n",
    "        index[y[I]].append(I)\n",
    "    \n",
    "    minimumPoint = min([len(I) for I in index.values()])    \n",
    "    \n",
    "    #Memastikan jumlah (+) dan (-) sama\n",
    "    for I in index:\n",
    "        if mode == 'CV':\n",
    "            chosen = random.sample(index[I],minimumPoint)\n",
    "        else:\n",
    "            chosen = random.choices(index[I],k=minimumPoint)\n",
    "        for J in chosen:\n",
    "            balancedX.append(X[J])\n",
    "            balancedY.append(y[J])\n",
    "    return balancedX, balancedY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(text):\n",
    "    listNews = []\n",
    "    for news in text:\n",
    "        listSentence = []\n",
    "        oldText = news\n",
    "        while True:\n",
    "            newText = oldText.replace(\"  \",\" \")\n",
    "            if oldText == newText:\n",
    "                break\n",
    "            oldText = newText\n",
    "        listSentence.extend(newText)\n",
    "        splitText = newText.split(\" \")\n",
    "        listSentence.append(\" \".join([splitText[I] for I in range(0,len(splitText),2)]))\n",
    "        listSentence.append(\" \".join([splitText[I] for I in range(1,len(splitText),2)]))\n",
    "        listNews.append(\" SNIP \".join(listSentence))\n",
    "    return listNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitGroup(kFold):\n",
    "    #Me too lazy to plug in sklearn\n",
    "    assert len(X) == len(y)\n",
    "    index = [int(I) for I in range(len(X))]\n",
    "    random.shuffle(index)\n",
    "    group = [index[len(index)*I//kFold:len(index)*(I+1)//kFold] for I in range(kFold)]\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Custom class for GradientBoosting\n",
    "class Boosting():\n",
    "    def __init__(self):\n",
    "        self.clf = GB()\n",
    "    def fit(self,X,y):\n",
    "        self.clf.fit(X,y)\n",
    "    def predict(self,X):\n",
    "        m = int(X.shape[0] ** (0.5))\n",
    "        pred = []\n",
    "        for I in range(m):\n",
    "            pred.extend(self.clf.predict(X[I*X.shape[0]//m:(I+1)*X.shape[0]//m].toarray()))\n",
    "        return pred\n",
    "#Custom class for K Nearest Neighbor\n",
    "class Neighbors:\n",
    "    def __init__(self):\n",
    "        self.clf = KNC()\n",
    "    def fit(self,X,y):\n",
    "        self.clf.fit(X,y)\n",
    "    def predict(self,X):\n",
    "        m = int(X.shape[0] ** (0.5))\n",
    "        pred = []\n",
    "        for I in range(m):\n",
    "            pred.extend(self.clf.predict(X[I*X.shape[0]//m:(I+1)*X.shape[0]//m]))\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bersihkanTeksBerita(array):\n",
    "    hasil = []\n",
    "    for news in array:\n",
    "        newSentence = \"\"\n",
    "        for J in news:\n",
    "            if J.isalpha():\n",
    "                newSentence += J\n",
    "            else:\n",
    "                newSentence += \" \"\n",
    "        hasil.append(newSentence)\n",
    "    return hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfOption = [Boosting(),LR(n_jobs = -1),NB(),LinearSVC(),Neighbors(),RFC()]\n",
    "mrePred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mrc(pred,Y):\n",
    "    assert len(pred)==len(Y)\n",
    "    pred = array(pred)\n",
    "    Y    = array(Y)\n",
    "    \n",
    "    TP, FP , TN, FN = 0,0,0,0\n",
    "    \n",
    "    for I in range(len(pred)):\n",
    "        if pred[I] == Y[I]:\n",
    "            if pred[I] == 1:\n",
    "                TP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "        else:\n",
    "            if pred[I] == -1:\n",
    "                FP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "    print(TP,FP,TN,FN)\n",
    "    try:\n",
    "        return ((TP*TN)-(FP*FN)) / ((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))**(0.5)\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del result\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mulai\n"
     ]
    }
   ],
   "source": [
    "print(\"Mulai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai pengambilan data\n",
      "Memulai CV\n",
      "710 1422 1195 291\n",
      "1824 308 346 1140\n",
      "1102 1030 1047 439\n",
      "1752 380 450 1036\n",
      "853 1279 1021 465\n",
      "1207 925 943 543\n",
      "741 1369 1175 333\n",
      "1762 348 367 1141\n",
      "1125 985 993 515\n",
      "1670 440 478 1030\n",
      "1690 420 411 1097\n",
      "1191 919 951 557\n",
      "721 1471 1195 231\n",
      "1899 293 279 1147\n",
      "1169 1023 983 443\n",
      "1822 370 397 1029\n",
      "1692 500 491 935\n",
      "1263 929 908 518\n",
      "703 1476 1191 248\n",
      "1879 300 278 1161\n",
      "1139 1040 983 456\n",
      "1785 394 376 1063\n",
      "1327 852 720 719\n",
      "1244 935 928 511\n",
      "664 1475 1221 259\n",
      "1834 305 257 1223\n",
      "1051 1088 1033 447\n",
      "1791 348 356 1124\n",
      "1950 189 210 1270\n",
      "1201 938 927 553\n",
      "Mulai training\n",
      "7109 14501 8015 3798\n",
      "22 134 77 11\n",
      "20389 1221 786 11027\n",
      "156 0 0 88\n",
      "10781 10829 6397 5416\n",
      "75 81 57 31\n",
      "19479 2131 1355 10458\n",
      "156 0 0 88\n",
      "18804 2806 1638 10175\n",
      "155 1 0 88\n",
      "13255 8355 4818 6995\n",
      "128 28 26 62\n",
      "Memulai pengambilan data\n",
      "Memulai CV\n",
      "1421 2918 1830 515\n",
      "3482 857 651 1694\n",
      "2185 2154 1530 815\n",
      "3334 1005 790 1555\n",
      "2901 1438 1015 1330\n",
      "2342 1997 1457 888\n",
      "3155 1146 855 1529\n",
      "3443 858 691 1693\n",
      "2007 2294 1643 741\n",
      "3285 1016 829 1555\n",
      "2797 1504 1065 1319\n",
      "2285 2016 1477 907\n",
      "1206 3054 2029 395\n",
      "3606 654 609 1815\n",
      "2304 1956 1560 864\n",
      "3393 867 829 1595\n",
      "2447 1813 1287 1137\n",
      "2243 2017 1553 871\n",
      "1468 2814 1867 536\n",
      "3547 735 580 1823\n",
      "2125 2157 1630 773\n",
      "3403 879 756 1647\n",
      "2708 1574 1189 1214\n",
      "2395 1887 1495 908\n",
      "1168 3151 1977 389\n",
      "3504 815 647 1719\n",
      "2079 2240 1645 721\n",
      "3366 953 813 1553\n",
      "2610 1709 1143 1223\n",
      "2337 1982 1493 873\n",
      "Mulai training\n",
      "21007 8072 5412 14166\n",
      "198 17 16 136\n",
      "25737 3342 2400 17178\n",
      "215 0 0 152\n",
      "15136 13943 9336 10242\n",
      "128 87 58 94\n",
      "24302 4777 3393 16185\n",
      "213 2 1 151\n",
      "19278 9801 6491 13087\n",
      "192 23 11 141\n",
      "17814 11265 7259 12319\n",
      "164 51 28 124\n",
      "Memulai pengambilan data\n",
      "Memulai CV\n",
      "1481 4368 3275 607\n",
      "4549 1300 1172 2710\n",
      "3068 2781 2449 1433\n",
      "4237 1612 1454 2428\n",
      "3271 2578 2165 1717\n"
     ]
    }
   ],
   "source": [
    "mrePred = []\n",
    "for iter in range(5):\n",
    "    print(\"Memulai pengambilan data\")\n",
    "    mreTotal = []\n",
    "    query = \"Select * from berita WHERE Date <= \"+str(date[iter])\n",
    "    c.execute(query)\n",
    "    trainData = c.fetchall()\n",
    "    \n",
    "    \n",
    "    query = \"Select * from berita WHERE Date <= \"+str(date[iter+1])+\" AND \"+str(date[iter])\n",
    "    c.execute(query)\n",
    "    testData = c.fetchall()\n",
    "    # Do cross-validation to choose the best feature selection\n",
    "    \n",
    "    X = bersihkanTeksBerita([I[3] for I in trainData])\n",
    "    y = [I[7] for I in trainData]\n",
    "    \n",
    "    # Mengurangi memori\n",
    "    del trainData\n",
    "    \n",
    "    print(\"Memulai CV\")       \n",
    "    group = splitGroup(5)\n",
    "    XkFold = [[X[J] for J in K]for K in group]\n",
    "    YkFold = [[y[J] for J in K]for K in group]\n",
    "    counterList = []\n",
    "    selectList = []\n",
    "    mreTotal = []\n",
    "  \n",
    "    for I in range(5):\n",
    "        xTrain = []\n",
    "        yTrain = []\n",
    "    \n",
    "        xTest  = []\n",
    "        yTest = []\n",
    "        \n",
    "        for J in range(5):\n",
    "            if J != I:\n",
    "                xTrain.extend(XkFold[J])\n",
    "                yTrain.extend(YkFold[J])\n",
    "            else:\n",
    "                testIndex = J\n",
    "\n",
    "        xTrain = transform(xTrain)\n",
    "        xTest = transform(XkFold[testIndex])\n",
    "\n",
    "        assert len(xTrain) == len(yTrain)\n",
    "        xTrainNew , yTrainNew = balancedTrain(xTrain,yTrain,'CV')\n",
    "        counterList.append(CV(ngram_range=(2,2),min_df=5)) \n",
    "        trainVector = counterList[-1].fit_transform(xTrainNew)\n",
    "        testVector  = counterList[-1].transform(xTest)\n",
    "\n",
    "        selectList.append(SelectKBest(chi2, k = min(10000,trainVector.shape[1])))\n",
    "\n",
    "        trainVector = selectList[-1].fit_transform(trainVector,yTrainNew)\n",
    "        testVector  = selectList[-1].transform(testVector)\n",
    "\n",
    "        mreTotal.append(0)\n",
    "        for J in clfOption:\n",
    "            J.fit(trainVector,yTrainNew)\n",
    "            prediction = J.predict(testVector)\n",
    "            mreTotal[-1] += mrc(prediction,YkFold[testIndex])\n",
    "    \n",
    "    index = mreTotal.index(max(mreTotal))\n",
    "    \n",
    "    mrePred.append({'post':[],\n",
    "                    'chronological':[]})\n",
    "    \n",
    "    xTrainNew = []\n",
    "    yTrainNew = []\n",
    "    # Generating boosting data\n",
    "    for I in range(5):\n",
    "        X_temp , y_temp = balancedTrain(xTrain,yTrain,'Boosting')\n",
    "        xTrainNew.append(X_temp)\n",
    "        yTrainNew.append(y_temp)\n",
    "\n",
    "    trainVector = [counterList[index].transform(I) for I in xTrainNew]        \n",
    "    trainVector = [selectList[index].transform(I)for I in trainVector]\n",
    "        \n",
    "    # Create the test set of chronological entries\n",
    "        \n",
    "    lengthOfTestData = {}\n",
    "    testX = []\n",
    "    dataY = {}\n",
    "\n",
    "    for entry in testData:\n",
    "        if entry[5] not in lengthOfTestData:\n",
    "            lengthOfTestData[entry[5]] = 0\n",
    "            dataY[entry[5]] = entry[7]\n",
    "        lengthOfTestData[entry[5]] += 1\n",
    "        testX.append(entry[3])\n",
    "    \n",
    "    testX = counterList[index].transform(transform(testX))\n",
    "    testVector = selectList[index].transform(testX)\n",
    "    print(\"Mulai training\")\n",
    "    for I in clfOption:\n",
    "        postPredict = array([int(0) for J in range(testVector.shape[0])])\n",
    "        for boostingIter in range(5):\n",
    "            I.fit(trainVector[boostingIter],yTrainNew[boostingIter])\n",
    "            postPredict += I.predict(testVector)\n",
    "        postPredict = [[-1,1][J>0] for J in postPredict]\n",
    "\n",
    "        dayPredict = []\n",
    "        postY = []\n",
    "        dayY = []\n",
    "        sumIndex = 0\n",
    "\n",
    "        for dateTested in lengthOfTestData:               \n",
    "            dayPredict.append([-1,1][sum(postPredict[sumIndex:sumIndex+lengthOfTestData[dateTested]])>0])\n",
    "            postY.extend([dataY[dateTested] for I in range(lengthOfTestData[dateTested])])\n",
    "            dayY.append(dataY[dateTested])\n",
    "            sumIndex += lengthOfTestData[dateTested]\n",
    "\n",
    "        mrePred[-1]['post'].append(mrc(postPredict,postY))\n",
    "        mrePred[-1]['chronological'].append(mrc(dayPredict,dayY))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting -> (chronological) 0.000259 (post) 0.013011 \n",
      "Logistic Regression -> (chronological) 0.008833 (post) 0.019391 \n",
      "Naive Bayes -> (chronological) 0.018590 (post) 0.019025 \n",
      "Linear SVC -> (chronological) 0.000854 (post) 0.019949 \n",
      "K nearest neighbor -> (chronological) 0.045772 (post) 0.015734 \n",
      "Random forest -> (chronological) 0.028655 (post) 0.017214 \n"
     ]
    }
   ],
   "source": [
    "name = [\"Gradient Boosting\",\"Logistic Regression\",\"Naive Bayes\",\"Linear SVC\",\"K nearest neighbor\",\"Random forest\"]\n",
    "for I in range(len(name)):\n",
    "    chronological = [J['chronological'][I] for J in mrePred]\n",
    "    post = [J['post'][I] for J in mrePred]\n",
    "    print(\"%s -> (chronological) %f (post) %f \" % (name[I],sum(chronological)/5,sum(post)/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chronological': [-0.08041741036528247,\n",
       "   -0.00903425307795571,\n",
       "   0.060263040633680896,\n",
       "   -0.012940520237177025,\n",
       "   0.07719184171054305,\n",
       "   0.03357044648161351],\n",
       "  'post': [0.004039105992426345,\n",
       "   0.035046231501828444,\n",
       "   0.03866386321371173,\n",
       "   0.03893165512341328,\n",
       "   0.011314922078974471,\n",
       "   0.02493921602405859]},\n",
       " {'chronological': [-0.029912249562631926,\n",
       "   -0.03552317266337992,\n",
       "   -0.0263179260078171,\n",
       "   -0.04023941963382059,\n",
       "   -0.04536780536262693,\n",
       "   -0.05792269894721858],\n",
       "  'post': [-0.02259194834389064,\n",
       "   -0.0006551549366040136,\n",
       "   -0.014682214448911015,\n",
       "   -0.002157793701502563,\n",
       "   0.008281815485184486,\n",
       "   -0.028418858537299908]},\n",
       " {'chronological': [-0.01611601285437681,\n",
       "   0.02375866681202409,\n",
       "   0.01581961698419295,\n",
       "   -0.002935163924097879,\n",
       "   0.1504460220535426,\n",
       "   0.08855539127335335],\n",
       "  'post': [0.02280172255273168,\n",
       "   0.003309469206891995,\n",
       "   0.013050911297837453,\n",
       "   0.003592007967474261,\n",
       "   0.03169339785935832,\n",
       "   0.034775158053151976]},\n",
       " {'chronological': [0.12774059265214632,\n",
       "   0.06496507099328451,\n",
       "   0.0431842430113855,\n",
       "   0.0603870681589546,\n",
       "   0.04659051497909479,\n",
       "   0.0790720657925368],\n",
       "  'post': [0.06080376702734158,\n",
       "   0.059253621566892144,\n",
       "   0.05809125599676626,\n",
       "   0.059377271312829015,\n",
       "   0.027380368391077096,\n",
       "   0.0547730826682175]}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrePred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for I in clfOption:\n",
    "    postPredict = array([int(0) for J in range(testVector.shape[0])])\n",
    "    for boostingIter in range(5):\n",
    "        I.fit(trainVector[boostingIter],yTrainNew[boostingIter])\n",
    "        postPredict += I.predict(testVector)\n",
    "    postPredict = [[-1,1][J>0] for J in postPredict]\n",
    "        \n",
    "    dayPredict = []\n",
    "    postY = []\n",
    "    dayY = []\n",
    "    sumIndex = 0\n",
    "    \n",
    "    for date in lengthOfTestData:               \n",
    "        dayPredict.append([-1,1][sum(postPredict[sumIndex:sumIndex+lengthOfTestData[date]])>0])\n",
    "        postY.extend([dataY[date] for I in range(lengthOfTestData[date])])\n",
    "        dayY.append(dataY[date])\n",
    "        sumIndex += lengthOfTestData[date]\n",
    "            \n",
    "    mrePred[-1]['post'].append(mrc(postPredict,postY))\n",
    "    mrePred[-1]['chronological'].append(mrc(dayPredict,dayY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Mulai training\")\n",
    "    for I in clfOption:\n",
    "        postPredict = array([int(0) for J in range(testVector.shape[0])])\n",
    "        for boostingIter in range(5):\n",
    "            I.fit(trainVector[boostingIter],yTrainNew[boostingIter])\n",
    "            postPredict += I.predict(testVector)\n",
    "        postPredict = [[-1,1][J>0] for J in postPredict]\n",
    "        \n",
    "        dayPredict = []\n",
    "        postY = []\n",
    "        sumIndex = 0\n",
    "    \n",
    "        for date in entry:               \n",
    "            dayPredict.append([-1,1][sum(postPredict[sumIndex:sumIndex+len(lengthOfTestData[date])])>0])\n",
    "            postY.extend([label[J] for I in range(len(lengthOfTestData[date]))])\n",
    "            dayY.append(label[J])\n",
    "            sumIndex += len(data[J])\n",
    "            \n",
    "        mrePred[-1]['post'].append(mrc(postPredict,postY))\n",
    "        mrePred[-1]['chronological'].append(mrc(dayPredict,dayY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainVector.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
